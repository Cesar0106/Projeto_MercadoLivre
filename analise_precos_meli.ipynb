{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto – Scraper Mercado Livre  \n",
    "Coleta anúncios, extrai detalhes, remove colunas pouco povoadas e grava CSVs organizados por execução. A ideia surgiu através de uma necessidade de descobrir tendências de preços para produtos específicos no Mercado Livre. A ideia é pegar o máximo de informações possíveis de concorrentes para conseguir escolher o preço ideal dos produtos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação das bibliotecas\n",
    "\n",
    "Execute a célula de código abaixo **uma única vez** para instalar as\n",
    "dependências necessárias (ou pule se já estiverem no ambiente):\n",
    "\n",
    "* `requests`, `beautifulsoup4`, `lxml` – scraping  \n",
    "* `pandas` – manipulação de dados  \n",
    "* `tqdm` – barra de progresso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q requests beautifulsoup4 lxml pandas tqdm matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports e configuração global\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time, random, math, re, json, csv, os\n",
    "\n",
    "import requests, pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros editáveis\n",
    "Altere palavras-chave, nº de páginas, atrasos e nº de threads.\n",
    "\n",
    "Nessa célula definimos os produtos que estamos pesquisando, quantidade de threads usadas e outros parâmentros que direcionam o código.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS        = [\"iphone-13\", \"iphone-14\", \"rtx-3060\", \"mac-mini-m4\"]\n",
    "PAGES_PER_KW    = 3               # páginas por keyword\n",
    "REQUEST_DELAY   = (0.1, 1)          # intervalo (seg) entre downloads\n",
    "MAX_WORKERS     = 12              # threads em paralelo\n",
    "KEEP_THRESHOLD  = 0.70            # ≥70 % valores não-nulos\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/124.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "ITEMS_PER_PAGE  = 48\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrutura de diretórios  \n",
    "Cada run cria `runs/<YYYYMMDD-HHMMSS>/raw/` e `clean/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TS   = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_DIR  = Path(\"runs\") / RUN_TS\n",
    "RAW_DIR  = RUN_DIR / \"raw\"\n",
    "CLN_DIR  = RUN_DIR / \"clean\"\n",
    "for d in (RAW_DIR, CLN_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Run dir:\", RUN_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares – busca\n",
    "Na célula abaixo definimos algumas funções que ajudam com o acesso as paginas do mercado livre na internet. Usamos BeautifulSoup para pegar os dados da pagina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_url(keyword: str, page: int) -> str:\n",
    "    base = f\"https://lista.mercadolivre.com.br/{keyword}\"\n",
    "    if page == 1:\n",
    "        return base\n",
    "    offset = (page - 1) * ITEMS_PER_PAGE + 1\n",
    "    return f\"{base}_Desde_{offset}\"\n",
    "\n",
    "def fetch_html(url: str) -> str:\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=20)\n",
    "    resp.raise_for_status()\n",
    "    return resp.text\n",
    "\n",
    "def parse_cards(html: str, kw: str) -> list[dict]:\n",
    "    soup  = BeautifulSoup(html, \"lxml\")\n",
    "    items = soup.select(\"li.ui-search-layout__item\")\n",
    "    rows  = []\n",
    "    for it in items:\n",
    "        a = (it.select_one('a[class*=\"poly-component__title\"]')\n",
    "             or it.select_one(\"a.ui-search-item__group__element\"))\n",
    "        if not a: continue\n",
    "        title = a.get_text(\" \", strip=True)\n",
    "        link  = a[\"href\"].split(\"#\")[0]\n",
    "        price_tag = it.select_one(\"span.andes-money-amount__fraction\")\n",
    "        price = int(re.sub(r\"[^\\d]\", \"\", price_tag.text)) if price_tag else None\n",
    "        ship = (it.select_one(\"div.poly-component__shipping\")\n",
    "                or it.select_one(\"span.ui-search-item__shipping-info\"))\n",
    "        shipping = ship.get_text(\" \", strip=True) if ship else None\n",
    "        seller_tag = it.select_one(\"span.poly-component__seller\")\n",
    "        seller = seller_tag.get_text(\" \", strip=True) if seller_tag else None\n",
    "        rows.append(dict(keyword=kw, title=title, price=price,\n",
    "                         url=link, shipping=shipping, seller=seller,\n",
    "                         scraped_at=datetime.now()))\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta de cards – paralela por página\n",
    "Utilizando threading para ter um código mais rápido e eficiente, pegamos os cards específicos das paginas para extrair as informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def scrape_keyword(keyword: str, pages: int) -> pd.DataFrame:\n",
    "    \"\"\"Busca TODAS as páginas de resultados em paralelo.\"\"\"\n",
    "    urls = [build_url(keyword, p) for p in range(1, pages + 1)]\n",
    "\n",
    "    rows = []\n",
    "    with ThreadPoolExecutor(max_workers=min(len(urls), MAX_WORKERS)) as ex:\n",
    "        fut_html = {ex.submit(fetch_html, u): u for u in urls}\n",
    "\n",
    "        for fut in tqdm(as_completed(fut_html),\n",
    "                        total=len(fut_html), desc=f\"{keyword} pages\"):\n",
    "            html = fut.result()\n",
    "            rows += parse_cards(html, keyword)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares – detalhes do anúncio\n",
    "Tendo em vista a estrutura da página, que foi obtida através da compreensão da estrutura da página, temos o método abaixo definindo quais partes da página o código deve procurar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_product(html: str) -> dict:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    out  = {}\n",
    "\n",
    "    t = soup.select_one(\"h1.ui-pdp-title\")\n",
    "    out[\"title_full\"] = t.get_text(\" \", strip=True) if t else None\n",
    "    p = soup.select_one(\"span.ui-pdp-price__second-line\")\n",
    "    if not p:\n",
    "        p = soup.select_one(\"span.andes-money-amount__fraction\")\n",
    "    if p: out[\"price_item\"] = int(re.sub(r\"[^\\d]\", \"\", p.text))\n",
    "    cond = soup.select_one(\"span.ui-pdp-subtitle\")\n",
    "    out[\"condition\"]   = cond.get_text(\" \", strip=True) if cond else None\n",
    "    sold = soup.select_one(\"span.ui-pdp-buybox__quantity__available\")\n",
    "    out[\"sold_qty\"]    = sold.get_text(\" \", strip=True) if sold else None\n",
    "    seller = soup.select_one(\"span.ui-pdp-seller__link-trigger\")\n",
    "    out[\"seller\"]      = seller.get_text(\" \", strip=True) if seller else None\n",
    "    st = soup.select_one(\"p.ui-pdp-seller__status-info\")\n",
    "    out[\"seller_status\"] = st.get_text(\" \", strip=True) if st else None\n",
    "    ship = soup.select_one(\"p.ui-pdp-color--GREEN, p.ui-pdp-color--BLACK\")\n",
    "    out[\"shipping\"]    = ship.get_text(\" \", strip=True) if ship else None\n",
    "\n",
    "    for row in soup.select(\"div.ui-vpp-striped-specs__table tr\"):\n",
    "        th = row.select_one(\"th\")\n",
    "        td = row.select_one(\"td span\")\n",
    "        if th and td:\n",
    "            key = re.sub(r\"\\W+\", \"_\", th.get_text(\" \", strip=True).lower()).strip(\"_\")\n",
    "            out[key] = td.get_text(\" \", strip=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visita de todos os anúncios – paralela por link\n",
    "A função abaixo ajuda com o acesso a todas as paginas de produtos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_with_details(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    details = []\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "        fut_det = {\n",
    "            ex.submit(fetch_html, url): url\n",
    "            for url in df[\"url\"].unique()\n",
    "        }\n",
    "        for fut in tqdm(as_completed(fut_det), total=len(fut_det), desc=\"Detalhes\"):\n",
    "            url = fut_det[fut]\n",
    "            try:\n",
    "                html = fut.result()\n",
    "                det  = parse_product(html)\n",
    "                det[\"url\"] = url\n",
    "                details.append(det)\n",
    "                time.sleep(random.uniform(*REQUEST_DELAY))\n",
    "            except Exception as e:\n",
    "                print(f\"Detalhe {url[:60]}…: {e}\")\n",
    "    det_df = pd.DataFrame(details)\n",
    "    return df.merge(det_df, on=\"url\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza – remove colunas inuteis (<70 % não-nulos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sparse_columns(df: pd.DataFrame, threshold=KEEP_THRESHOLD):\n",
    "    keep = [c for c in df.columns\n",
    "            if df[c].notna().mean() >= threshold]\n",
    "    return df[keep]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline completo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = []\n",
    "for kw in KEYWORDS:\n",
    "    cards = scrape_keyword(kw, PAGES_PER_KW)\n",
    "    cards.to_csv(RAW_DIR / f\"{kw}.csv\", index=False)\n",
    "    enriched = enrich_with_details(cards)\n",
    "    clean = drop_sparse_columns(enriched)\n",
    "    clean.to_csv(CLN_DIR / f\"{kw}_clean.csv\", index=False)\n",
    "    all_stats.append(\n",
    "        dict(keyword=kw,\n",
    "             raw_rows=len(cards),\n",
    "             clean_rows=len(clean),\n",
    "             kept_cols=len(clean.columns))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relatório final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.DataFrame(all_stats)\n",
    "print(report)\n",
    "print(\"\\nArquivos gravados em:\", RUN_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise exploratória — visão geral\n",
    "\n",
    "Carregamos todos os arquivos `*_clean.csv` gerados na **execução mais\n",
    "recente** (`runs/<timestamp>/clean/`) e calculamos:\n",
    "\n",
    "| métrica | descrição |\n",
    "| ------- | ---------- |\n",
    "| **n_itens**      | total de anúncios por palavra-chave |\n",
    "| **preço_médio**  | média simples do preço (R$)          |\n",
    "| **preço_mín / preço_máx** | limites inferior e superior, úteis para detectar outliers |\n",
    "\n",
    "Também listamos os **10 títulos de anúncio mais frequentes**.\n",
    "\n",
    "> Se ainda não existir nenhuma pasta `runs/<timestamp>/clean/`\n",
    "> execute primeiro o pipeline de *scraping* ➜ *cleaning*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "BASE_DIR   = Path.cwd()          # pasta do notebook\n",
    "RUNS_DIR   = BASE_DIR / \"runs\"   # onde ficam as execuções\n",
    "\n",
    "run_folders = sorted([p for p in RUNS_DIR.iterdir() if p.is_dir()])\n",
    "if not run_folders:\n",
    "    raise FileNotFoundError(f\"Nenhuma pasta encontrada em {RUNS_DIR}\")\n",
    "\n",
    "latest_run  = run_folders[-1]\n",
    "clean_path  = latest_run / \"clean\"\n",
    "print(f\"Usando dados de: {clean_path.relative_to(BASE_DIR)}\")\n",
    "\n",
    "csv_files   = list(clean_path.glob(\"*_clean.csv\"))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"Nenhum *_clean.csv encontrado na pasta 'clean/'\")\n",
    "\n",
    "df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "\n",
    "metrics = (\n",
    "    df.groupby(\"keyword\")\n",
    "      .agg(\n",
    "          n_itens     = (\"price\", \"count\"),\n",
    "          preço_médio = (\"price\", \"mean\"),\n",
    "          preço_mín   = (\"price\", \"min\"),\n",
    "          preço_máx   = (\"price\", \"max\"),\n",
    "      )\n",
    "      .round(2)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "top_titles = (\n",
    "    df[\"title\"]\n",
    "      .value_counts()\n",
    "      .head(10)\n",
    "      .rename_axis(\"title\")\n",
    "      .reset_index(name=\"freq\")\n",
    ")\n",
    "\n",
    "print(\"\\n### Métricas por keyword\")\n",
    "display(metrics.style.format(\n",
    "    {\"preço_médio\": \"R${:,.2f}\",\n",
    "     \"preço_mín\":   \"R${:,.0f}\",\n",
    "     \"preço_máx\":   \"R${:,.0f}\"}\n",
    "))\n",
    "\n",
    "print(\"\\n### Títulos mais frequentes (Top-10)\")\n",
    "display(top_titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 · Análise aprofundada\n",
    "Nesta secção: limpeza fina da coluna **condition**, estatísticas e visualizações por *keyword*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "run_dir = max(Path(\"runs\").glob(\"*/clean\"), key=lambda p: p.parent.name)\n",
    "files = list(run_dir.glob(\"*.csv\"))\n",
    "data = {f.stem.replace(\"_clean\", \"\"): pd.read_csv(f) for f in files}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Normalização de **condition** → `condition` e `sold_qty`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_condition(df):\n",
    "    cond = df[\"condition\"].fillna(\"\").str.split(\"|\", n=1, expand=True)\n",
    "    df[\"condition\"] = cond[0].str.strip().replace(\"\", pd.NA)\n",
    "    df[\"sold_qty\"] = (\n",
    "        cond[1]\n",
    "        .str.extract(r\"(\\d[\\d\\.]*)\", expand=False)\n",
    "        .str.replace(\".\", \"\", regex=False)\n",
    "        .astype(\"Int64\")\n",
    "    )\n",
    "for k, d in data.items():\n",
    "    split_condition(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Métricas por *keyword*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for k, d in data.items():\n",
    "    price_stats = d[\"price\"].agg([\"mean\", \"median\", \"min\", \"max\"])\n",
    "    most = d[\"condition\"].mode(dropna=True)\n",
    "    least = d[\"condition\"].value_counts(dropna=True).idxmin()\n",
    "    avg_sales = d[\"sold_qty\"].mean()\n",
    "    metrics.append(\n",
    "        {\n",
    "            \"keyword\": k,\n",
    "            \"cond_mais_comum\": most.iloc[0] if not most.empty else pd.NA,\n",
    "            \"cond_mais_rara\": least,\n",
    "            \"preco_medio\": price_stats[\"mean\"],\n",
    "            \"preco_mediana\": price_stats[\"median\"],\n",
    "            \"preco_min\": price_stats[\"min\"],\n",
    "            \"preco_max\": price_stats[\"max\"],\n",
    "            \"vendas_medias\": avg_sales,\n",
    "        }\n",
    "    )\n",
    "pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Anúncio com maior número de vendas por *keyword*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = []\n",
    "for k, d in data.items():\n",
    "    top = d.sort_values(\"sold_qty\", ascending=False).iloc[0]\n",
    "    tops.append({\"keyword\": k, \"sold_qty\": top[\"sold_qty\"], \"title\": top[\"title\"]})\n",
    "pd.DataFrame(tops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Distribuição de preços  \n",
    "Histogramas por *keyword* (um gráfico por produto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, d in data.items():\n",
    "    d[\"price\"].dropna().plot.hist(\n",
    "        bins=20,\n",
    "        title=f\"Distribuição de preços – {k}\",\n",
    "        xlabel=\"Preço (R$)\",\n",
    "        ylabel=\"Frequência\",\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Distribuição de vendas  \n",
    "Histogramas por *keyword* (um gráfico por produto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, d in data.items():\n",
    "    d[\"sold_qty\"].dropna().plot.hist(\n",
    "        bins=20,\n",
    "        title=f\"Distribuição de vendas – {k}\",\n",
    "        xlabel=\"Unidades vendidas\",\n",
    "        ylabel=\"Frequência\",\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo\n",
    "Esse código acaba sendo muito útil para ajudar a tirar informações de mercado sobre produtos específicos no Brasi. Para ver os resultados e filtrar as informações desejadas, é só acessar o arquivo gerado na aba clean, que tem os dados limpos e filtrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
